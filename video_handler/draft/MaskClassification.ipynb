{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bde53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2be32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with_mask', 'without_mask']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/train'\n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "    train_transforms = transforms.Compose([transforms.Resize(200),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])    \n",
    "    test_transforms = transforms.Compose([transforms.Resize(200),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      ])    \n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=test_transforms)    \n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=8)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=8)\n",
    "    return trainloader, testloader \n",
    "\n",
    "trainloader,testloader = load_split_train_test(data_dir, .2)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd726f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51d6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 100, 100]             432\n",
      "       BatchNorm2d-2         [-1, 16, 100, 100]              32\n",
      "         Hardswish-3         [-1, 16, 100, 100]               0\n",
      "            Conv2d-4         [-1, 16, 100, 100]             144\n",
      "       BatchNorm2d-5         [-1, 16, 100, 100]              32\n",
      "              ReLU-6         [-1, 16, 100, 100]               0\n",
      "            Conv2d-7         [-1, 16, 100, 100]             256\n",
      "       BatchNorm2d-8         [-1, 16, 100, 100]              32\n",
      "          Identity-9         [-1, 16, 100, 100]               0\n",
      " InvertedResidual-10         [-1, 16, 100, 100]               0\n",
      "           Conv2d-11         [-1, 64, 100, 100]           1,024\n",
      "      BatchNorm2d-12         [-1, 64, 100, 100]             128\n",
      "             ReLU-13         [-1, 64, 100, 100]               0\n",
      "           Conv2d-14           [-1, 64, 50, 50]             576\n",
      "      BatchNorm2d-15           [-1, 64, 50, 50]             128\n",
      "             ReLU-16           [-1, 64, 50, 50]               0\n",
      "           Conv2d-17           [-1, 24, 50, 50]           1,536\n",
      "      BatchNorm2d-18           [-1, 24, 50, 50]              48\n",
      "         Identity-19           [-1, 24, 50, 50]               0\n",
      " InvertedResidual-20           [-1, 24, 50, 50]               0\n",
      "           Conv2d-21           [-1, 72, 50, 50]           1,728\n",
      "      BatchNorm2d-22           [-1, 72, 50, 50]             144\n",
      "             ReLU-23           [-1, 72, 50, 50]               0\n",
      "           Conv2d-24           [-1, 72, 50, 50]             648\n",
      "      BatchNorm2d-25           [-1, 72, 50, 50]             144\n",
      "             ReLU-26           [-1, 72, 50, 50]               0\n",
      "           Conv2d-27           [-1, 24, 50, 50]           1,728\n",
      "      BatchNorm2d-28           [-1, 24, 50, 50]              48\n",
      "         Identity-29           [-1, 24, 50, 50]               0\n",
      " InvertedResidual-30           [-1, 24, 50, 50]               0\n",
      "           Conv2d-31           [-1, 72, 50, 50]           1,728\n",
      "      BatchNorm2d-32           [-1, 72, 50, 50]             144\n",
      "             ReLU-33           [-1, 72, 50, 50]               0\n",
      "           Conv2d-34           [-1, 72, 25, 25]           1,800\n",
      "      BatchNorm2d-35           [-1, 72, 25, 25]             144\n",
      "             ReLU-36           [-1, 72, 25, 25]               0\n",
      "           Conv2d-37             [-1, 24, 1, 1]           1,752\n",
      "             ReLU-38             [-1, 24, 1, 1]               0\n",
      "           Conv2d-39             [-1, 72, 1, 1]           1,800\n",
      "SqueezeExcitation-40           [-1, 72, 25, 25]               0\n",
      "           Conv2d-41           [-1, 40, 25, 25]           2,880\n",
      "      BatchNorm2d-42           [-1, 40, 25, 25]              80\n",
      "         Identity-43           [-1, 40, 25, 25]               0\n",
      " InvertedResidual-44           [-1, 40, 25, 25]               0\n",
      "           Conv2d-45          [-1, 120, 25, 25]           4,800\n",
      "      BatchNorm2d-46          [-1, 120, 25, 25]             240\n",
      "             ReLU-47          [-1, 120, 25, 25]               0\n",
      "           Conv2d-48          [-1, 120, 25, 25]           3,000\n",
      "      BatchNorm2d-49          [-1, 120, 25, 25]             240\n",
      "             ReLU-50          [-1, 120, 25, 25]               0\n",
      "           Conv2d-51             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-52             [-1, 32, 1, 1]               0\n",
      "           Conv2d-53            [-1, 120, 1, 1]           3,960\n",
      "SqueezeExcitation-54          [-1, 120, 25, 25]               0\n",
      "           Conv2d-55           [-1, 40, 25, 25]           4,800\n",
      "      BatchNorm2d-56           [-1, 40, 25, 25]              80\n",
      "         Identity-57           [-1, 40, 25, 25]               0\n",
      " InvertedResidual-58           [-1, 40, 25, 25]               0\n",
      "           Conv2d-59          [-1, 120, 25, 25]           4,800\n",
      "      BatchNorm2d-60          [-1, 120, 25, 25]             240\n",
      "             ReLU-61          [-1, 120, 25, 25]               0\n",
      "           Conv2d-62          [-1, 120, 25, 25]           3,000\n",
      "      BatchNorm2d-63          [-1, 120, 25, 25]             240\n",
      "             ReLU-64          [-1, 120, 25, 25]               0\n",
      "           Conv2d-65             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-66             [-1, 32, 1, 1]               0\n",
      "           Conv2d-67            [-1, 120, 1, 1]           3,960\n",
      "SqueezeExcitation-68          [-1, 120, 25, 25]               0\n",
      "           Conv2d-69           [-1, 40, 25, 25]           4,800\n",
      "      BatchNorm2d-70           [-1, 40, 25, 25]              80\n",
      "         Identity-71           [-1, 40, 25, 25]               0\n",
      " InvertedResidual-72           [-1, 40, 25, 25]               0\n",
      "           Conv2d-73          [-1, 240, 25, 25]           9,600\n",
      "      BatchNorm2d-74          [-1, 240, 25, 25]             480\n",
      "        Hardswish-75          [-1, 240, 25, 25]               0\n",
      "           Conv2d-76          [-1, 240, 13, 13]           2,160\n",
      "      BatchNorm2d-77          [-1, 240, 13, 13]             480\n",
      "        Hardswish-78          [-1, 240, 13, 13]               0\n",
      "           Conv2d-79           [-1, 80, 13, 13]          19,200\n",
      "      BatchNorm2d-80           [-1, 80, 13, 13]             160\n",
      "         Identity-81           [-1, 80, 13, 13]               0\n",
      " InvertedResidual-82           [-1, 80, 13, 13]               0\n",
      "           Conv2d-83          [-1, 200, 13, 13]          16,000\n",
      "      BatchNorm2d-84          [-1, 200, 13, 13]             400\n",
      "        Hardswish-85          [-1, 200, 13, 13]               0\n",
      "           Conv2d-86          [-1, 200, 13, 13]           1,800\n",
      "      BatchNorm2d-87          [-1, 200, 13, 13]             400\n",
      "        Hardswish-88          [-1, 200, 13, 13]               0\n",
      "           Conv2d-89           [-1, 80, 13, 13]          16,000\n",
      "      BatchNorm2d-90           [-1, 80, 13, 13]             160\n",
      "         Identity-91           [-1, 80, 13, 13]               0\n",
      " InvertedResidual-92           [-1, 80, 13, 13]               0\n",
      "           Conv2d-93          [-1, 184, 13, 13]          14,720\n",
      "      BatchNorm2d-94          [-1, 184, 13, 13]             368\n",
      "        Hardswish-95          [-1, 184, 13, 13]               0\n",
      "           Conv2d-96          [-1, 184, 13, 13]           1,656\n",
      "      BatchNorm2d-97          [-1, 184, 13, 13]             368\n",
      "        Hardswish-98          [-1, 184, 13, 13]               0\n",
      "           Conv2d-99           [-1, 80, 13, 13]          14,720\n",
      "     BatchNorm2d-100           [-1, 80, 13, 13]             160\n",
      "        Identity-101           [-1, 80, 13, 13]               0\n",
      "InvertedResidual-102           [-1, 80, 13, 13]               0\n",
      "          Conv2d-103          [-1, 184, 13, 13]          14,720\n",
      "     BatchNorm2d-104          [-1, 184, 13, 13]             368\n",
      "       Hardswish-105          [-1, 184, 13, 13]               0\n",
      "          Conv2d-106          [-1, 184, 13, 13]           1,656\n",
      "     BatchNorm2d-107          [-1, 184, 13, 13]             368\n",
      "       Hardswish-108          [-1, 184, 13, 13]               0\n",
      "          Conv2d-109           [-1, 80, 13, 13]          14,720\n",
      "     BatchNorm2d-110           [-1, 80, 13, 13]             160\n",
      "        Identity-111           [-1, 80, 13, 13]               0\n",
      "InvertedResidual-112           [-1, 80, 13, 13]               0\n",
      "          Conv2d-113          [-1, 480, 13, 13]          38,400\n",
      "     BatchNorm2d-114          [-1, 480, 13, 13]             960\n",
      "       Hardswish-115          [-1, 480, 13, 13]               0\n",
      "          Conv2d-116          [-1, 480, 13, 13]           4,320\n",
      "     BatchNorm2d-117          [-1, 480, 13, 13]             960\n",
      "       Hardswish-118          [-1, 480, 13, 13]               0\n",
      "          Conv2d-119            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-120            [-1, 120, 1, 1]               0\n",
      "          Conv2d-121            [-1, 480, 1, 1]          58,080\n",
      "SqueezeExcitation-122          [-1, 480, 13, 13]               0\n",
      "          Conv2d-123          [-1, 112, 13, 13]          53,760\n",
      "     BatchNorm2d-124          [-1, 112, 13, 13]             224\n",
      "        Identity-125          [-1, 112, 13, 13]               0\n",
      "InvertedResidual-126          [-1, 112, 13, 13]               0\n",
      "          Conv2d-127          [-1, 672, 13, 13]          75,264\n",
      "     BatchNorm2d-128          [-1, 672, 13, 13]           1,344\n",
      "       Hardswish-129          [-1, 672, 13, 13]               0\n",
      "          Conv2d-130          [-1, 672, 13, 13]           6,048\n",
      "     BatchNorm2d-131          [-1, 672, 13, 13]           1,344\n",
      "       Hardswish-132          [-1, 672, 13, 13]               0\n",
      "          Conv2d-133            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-134            [-1, 168, 1, 1]               0\n",
      "          Conv2d-135            [-1, 672, 1, 1]         113,568\n",
      "SqueezeExcitation-136          [-1, 672, 13, 13]               0\n",
      "          Conv2d-137          [-1, 112, 13, 13]          75,264\n",
      "     BatchNorm2d-138          [-1, 112, 13, 13]             224\n",
      "        Identity-139          [-1, 112, 13, 13]               0\n",
      "InvertedResidual-140          [-1, 112, 13, 13]               0\n",
      "          Conv2d-141          [-1, 672, 13, 13]          75,264\n",
      "     BatchNorm2d-142          [-1, 672, 13, 13]           1,344\n",
      "       Hardswish-143          [-1, 672, 13, 13]               0\n",
      "          Conv2d-144            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-145            [-1, 672, 7, 7]           1,344\n",
      "       Hardswish-146            [-1, 672, 7, 7]               0\n",
      "          Conv2d-147            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-148            [-1, 168, 1, 1]               0\n",
      "          Conv2d-149            [-1, 672, 1, 1]         113,568\n",
      "SqueezeExcitation-150            [-1, 672, 7, 7]               0\n",
      "          Conv2d-151            [-1, 160, 7, 7]         107,520\n",
      "     BatchNorm2d-152            [-1, 160, 7, 7]             320\n",
      "        Identity-153            [-1, 160, 7, 7]               0\n",
      "InvertedResidual-154            [-1, 160, 7, 7]               0\n",
      "          Conv2d-155            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-156            [-1, 960, 7, 7]           1,920\n",
      "       Hardswish-157            [-1, 960, 7, 7]               0\n",
      "          Conv2d-158            [-1, 960, 7, 7]          24,000\n",
      "     BatchNorm2d-159            [-1, 960, 7, 7]           1,920\n",
      "       Hardswish-160            [-1, 960, 7, 7]               0\n",
      "          Conv2d-161            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-162            [-1, 240, 1, 1]               0\n",
      "          Conv2d-163            [-1, 960, 1, 1]         231,360\n",
      "SqueezeExcitation-164            [-1, 960, 7, 7]               0\n",
      "          Conv2d-165            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-166            [-1, 160, 7, 7]             320\n",
      "        Identity-167            [-1, 160, 7, 7]               0\n",
      "InvertedResidual-168            [-1, 160, 7, 7]               0\n",
      "          Conv2d-169            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-170            [-1, 960, 7, 7]           1,920\n",
      "       Hardswish-171            [-1, 960, 7, 7]               0\n",
      "          Conv2d-172            [-1, 960, 7, 7]          24,000\n",
      "     BatchNorm2d-173            [-1, 960, 7, 7]           1,920\n",
      "       Hardswish-174            [-1, 960, 7, 7]               0\n",
      "          Conv2d-175            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-176            [-1, 240, 1, 1]               0\n",
      "          Conv2d-177            [-1, 960, 1, 1]         231,360\n",
      "SqueezeExcitation-178            [-1, 960, 7, 7]               0\n",
      "          Conv2d-179            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-180            [-1, 160, 7, 7]             320\n",
      "        Identity-181            [-1, 160, 7, 7]               0\n",
      "InvertedResidual-182            [-1, 160, 7, 7]               0\n",
      "          Conv2d-183            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-184            [-1, 960, 7, 7]           1,920\n",
      "       Hardswish-185            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-186            [-1, 960, 1, 1]               0\n",
      "          Linear-187                 [-1, 1280]       1,230,080\n",
      "       Hardswish-188                 [-1, 1280]               0\n",
      "         Dropout-189                 [-1, 1280]               0\n",
      "          Linear-190                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 5,483,032\n",
      "Trainable params: 5,483,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 90.69\n",
      "Params size (MB): 20.92\n",
      "Estimated Total Size (MB): 112.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v3_large(pretrained = True)\n",
    "summary(model, (3, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6140cfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "  (1): Hardswish()\n",
       "  (2): Dropout(p=0.2, inplace=True)\n",
       "  (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cab00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "  nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "  nn.Hardswish(),\n",
    "  nn.Dropout(p=0.2, inplace=True),\n",
    "  nn.Linear(in_features=1280, out_features=1000, bias=True),\n",
    "  nn.Linear(in_features=1000, out_features=2, bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5fe042",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ee31cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): ConvBNActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (4): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9215dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14500/2045734807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlogps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "steps = 0\n",
    "epochs_no_improve=0\n",
    "n_epochs_stop = 6\n",
    "running_loss = 0\n",
    "print_every = 100\n",
    "min_val_loss = np.Inf\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model(inputs)  \n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(1)\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "            logps = model(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "            test_loss += batch_loss.item()\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy +=torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "    test_accuracy=round(accuracy/len(testloader,4))\n",
    "    epoch_losses =  np.mean(test_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "          f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "          f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    print(\"** Epoch {} ** - Epoch Time {}\".format(epoch, int(end-start)))\n",
    "    if epoch_losses < min_val_loss:\n",
    "        epochs_no_improve = 0\n",
    "        min_val_loss = epoch_losses\n",
    "        torch.save(model, 'best_model.pth')                \n",
    "    else:\n",
    "        print(2)\n",
    "        epochs_no_improve += 1\n",
    "    if epoch > 5 and epochs_no_improve == n_epochs_stop:\n",
    "        print('Early stopping!' )\n",
    "        early_stop = True\n",
    "    if early_stop:\n",
    "        print('stoppend')\n",
    "        break\n",
    "torch.save(model, 'aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323efd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea1a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afa168",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1=torch.load('aerialmodel.pth')\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model1(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc834f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
